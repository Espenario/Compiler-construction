{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dataclasses import dataclass\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L_Nums():\n",
    "    Tag_ERROR = 1\n",
    "    Tag_T = 2\n",
    "    Tag_Nt = 3\n",
    "    Tag_AXIOM = 4\n",
    "    Tag_COMMENT = 5\n",
    "    Tag_OPEN_GROUP = 6\n",
    "    Tag_CLOSE_GROUP = 7\n",
    "    Tag_UNMATCHED = 8\n",
    "    Tag_END = 9\n",
    "\n",
    "\n",
    "class Token:\n",
    "    \n",
    "    def __init__(self, tag = None, value = \"\"):\n",
    "        self.tag = tag\n",
    "        self.text = value\n",
    "\n",
    "class CoordsToken(Token):\n",
    "\n",
    "    def __init__ (self, tag = None, value = \"\", index_start = 0, index_end = 0):\n",
    "        self.tag = tag\n",
    "        self.text = value\n",
    "        self.index_start = index_start\n",
    "        self.index_end = index_end\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.tag) + '(' + str(self.index_start) + ',' + str(self.index_end) + '):' + str(self.text)\n",
    "\n",
    "class Lexer:\n",
    "\n",
    "    def token_matcher(self, text_input):\n",
    "\n",
    "        matched = re.match(r\"'.*\\n\", text_input)\n",
    "        if matched:\n",
    "            return Token(tag=L_Nums.Tag_COMMENT, value=matched.group())\n",
    "        matched = re.match(r\"<axiom <({})>>\\n\".format(r\"[A-Z]'?\"), text_input)\n",
    "        if matched:\n",
    "            return Token(tag=L_Nums.Tag_AXIOM, value=matched.group())\n",
    "        matched = re.match(\"<\", text_input)\n",
    "        if matched:\n",
    "            return Token(tag=L_Nums.Tag_OPEN_GROUP, value=matched.group())\n",
    "        matched = re.match(\">\", text_input)\n",
    "        if matched:\n",
    "            return Token(tag=L_Nums.Tag_CLOSE_GROUP, value=matched.group())\n",
    "        matched = re.match(r\"[a-z\\(\\)\\+\\*]\",text_input)\n",
    "        if matched:\n",
    "            return Token(tag=L_Nums.Tag_T, value=matched.group())\n",
    "        matched = re.match(r\"[A-Z]'?\", text_input)\n",
    "        if matched:\n",
    "            return Token(tag=L_Nums.Tag_Nt, value=matched.group())\n",
    "\n",
    "        return Token(tag=L_Nums.Tag_UNMATCHED, value=text_input[0])\n",
    "\n",
    "    def perform_tokenize(self, text_input):\n",
    "        new_tokens = Queue()\n",
    "        idx = 0\n",
    "\n",
    "        while idx < len(text_input):\n",
    "            token = self.token_matcher(text_input[idx:])\n",
    "            if token.tag == L_Nums.Tag_UNMATCHED and token.text.isspace() or token.tag == L_Nums.Tag_COMMENT:\n",
    "                idx += len(token.text)\n",
    "            else:\n",
    "                if token.tag == L_Nums.Tag_AXIOM:\n",
    "                    axiom_value = re.search(r\"[A-Z]'?\", text_input).group(0)\n",
    "                    t = CoordsToken(L_Nums.Tag_AXIOM, axiom_value, idx, idx + len(token.text))\n",
    "                    new_tokens.put(CoordsToken(L_Nums.Tag_AXIOM, axiom_value, idx, idx + len(token.text)))\n",
    "                else:\n",
    "                    new_tokens.put(CoordsToken(token.tag, token.text, idx, idx + len(token.text)))\n",
    "                idx += len(token.text)\n",
    "\n",
    "        new_tokens.put(CoordsToken(L_Nums.Tag_END, \"\", idx+1, idx+1))\n",
    "        return new_tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nt:\n",
    "    def __init__(self, str, id=0):\n",
    "        self.value = str\n",
    "        self.num_rule = id\n",
    "        self.accessors = []\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.value)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "    \n",
    "    def print(self, indent):\n",
    "        print(indent + str(self) + \":\")\n",
    "        for child in self.accessors:\n",
    "            child.print(indent + \"\\t\")\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (isinstance(other, Nt) and\n",
    "                self.value == other.value)\n",
    "\n",
    "\n",
    "class T:\n",
    "    def __init__(self, str):\n",
    "        self.value = str\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.value)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "    \n",
    "    def print(self, indent):\n",
    "        print(indent + str(self))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (isinstance(other, T) and\n",
    "                self.value == other.value)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "      \n",
    "    def print(self, indent=\"\"):\n",
    "        print(str(indent) + 'End Node:' + str(self.value))\n",
    "\n",
    "class Inner:\n",
    "    def __init__(self, non_term, id):\n",
    "        self.non_term = non_term\n",
    "        self.rule_id = id\n",
    "        self.accessors = []\n",
    "      \n",
    "    def print(self, indent=\"\"):\n",
    "        print(indent + 'Node:' + str(self.non_term) + ', value:' + str(self.rule_id))\n",
    "        for child in self.accessors:\n",
    "            child.print(indent + \"\\t\")\n",
    "\n",
    "class Rules_in_Table:\n",
    "    def __init__(self):\n",
    "        self.order_numbers = 0\n",
    "        self.rules = [(Nt(\"Programm\"), L_Nums.Tag_AXIOM), (Nt(\"LR\"), L_Nums.Tag_OPEN_GROUP),\n",
    "                      (Nt(\"LR\"), L_Nums.Tag_OPEN_GROUP), (Nt(\"RLR\"), L_Nums.Tag_END),\n",
    "                      (Nt(\"OR\"), L_Nums.Tag_OPEN_GROUP), (Nt(\"SR\"), L_Nums.Tag_OPEN_GROUP),\n",
    "                      (Nt(\"SRLR\"), L_Nums.Tag_OPEN_GROUP), (Nt(\"SRLR\"), L_Nums.Tag_CLOSE_GROUP),\n",
    "                      (Nt(\"SRLR\"), L_Nums.Tag_END), (Nt(\"SRT\"), L_Nums.Tag_OPEN_GROUP),\n",
    "                      (Nt(\"RLRTS\"), L_Nums.Tag_T), (Nt(\"RLRTS\"), L_Nums.Tag_Nt),\n",
    "                      (Nt(\"RLRTS\"), L_Nums.Tag_CLOSE_GROUP), (Nt(\"RLRTS\"), L_Nums.Tag_END),\n",
    "                      (Nt(\"RSF\"), L_Nums.Tag_T), (Nt(\"RSF\"), L_Nums.Tag_Nt),\n",
    "                      (Nt(\"RSF\"), L_Nums.Tag_CLOSE_GROUP)]\n",
    "        self.rhs_rules = [([T(\"Stmt_Axiom\"), Nt(\"LR\")], self.order_numbers + 1),\n",
    "                          ([Nt(\"OR\"), Nt(\"RLR\")], self.order_numbers + 1),\n",
    "                          ([Nt(\"OR\"), Nt(\"RLR\")], self.order_numbers + 1),\n",
    "                          ([], self.order_numbers + 1),\n",
    "                          ([T(\"OpenStmt\"), T(\"NtermStmt\"), Nt(\"SR\"), T(\"CloseStmt\")], self.order_numbers + 1),\n",
    "                          ([Nt(\"SRT\"), Nt(\"SRLR\")], self.order_numbers + 1),\n",
    "                          ([Nt(\"SRT\"), Nt(\"SRLR\")], self.order_numbers + 1),\n",
    "                          ([], self.order_numbers + 1),\n",
    "                          ([], self.order_numbers + 1),\n",
    "                          ([T(\"OpenStmt\"), Nt(\"RSF\"), Nt(\"RLRTS\"), T(\"CloseStmt\")], self.order_numbers + 1),\n",
    "                          ([Nt(\"RSF\"), Nt(\"RLRTS\")], self.order_numbers + 1),\n",
    "                          ([Nt(\"RSF\"), Nt(\"RLRTS\")], self.order_numbers + 1),\n",
    "                          ([], self.order_numbers + 1),\n",
    "                          ([], self.order_numbers + 1),\n",
    "                          ([T(\"Term\")], self.order_numbers + 1),\n",
    "                          ([T(\"NtermStmt\")], self.order_numbers + 1),\n",
    "                          ([], self.order_numbers + 1)\n",
    "        ]\n",
    "\n",
    "test_str = \"\"\"' аксиома\n",
    "<axiom <E>>\n",
    "' правила грамматики\n",
    "<E  <T E'>>\n",
    "' и это комментарий\n",
    "<E' <+ T E'> <>> \n",
    "<T  <F T'>>\n",
    "<T' <* F T'> 'и это комментарий\n",
    "\n",
    " <>>\n",
    "<F  <n> <( E )>>\"\"\"\n",
    "\n",
    "def top_down(tokens):\n",
    "    type_mapping = {\n",
    "        L_Nums.Tag_AXIOM: \"Stmt_Axiom\",\n",
    "        L_Nums.Tag_T: \"Term\",\n",
    "        L_Nums.Tag_Nt: \"NtermStmt\",\n",
    "        L_Nums.Tag_OPEN_GROUP: \"OpenStmt\",\n",
    "        L_Nums.Tag_CLOSE_GROUP: \"CloseStmt\"\n",
    "    }\n",
    "\n",
    "    delta = Rules_in_Table()\n",
    "    sparent = Inner(None, None)\n",
    "    stack = [(sparent, T('$')), (sparent, Nt('Programm'))]\n",
    "\n",
    "    token = tokens.get()\n",
    "    parent, X = stack.pop()\n",
    "    \n",
    "    while X.value != '$':\n",
    "        if isinstance(X, T):\n",
    "            if X.value == type_mapping[token.tag]:\n",
    "                parent.accessors.append(Leaf(token))\n",
    "                token = tokens.get()\n",
    "            else:\n",
    "                raise ValueError(f\"T. Ожидался {X}, Получен {token}\")\n",
    "        elif (X, token.tag) in delta.rules:\n",
    "            inner = Inner(X, delta.rhs_rules[delta.rules.find[X, token.tag][1]])\n",
    "            parent.accessors.append(inner)\n",
    "            for elem in delta.rhs_rules[delta.rules.find[X, token.tag]][0][::-1]:\n",
    "                stack.append((inner, elem))\n",
    "        else:\n",
    "            raise ValueError(f\"Ожидался {X}, Получен {token}\")\n",
    "        \n",
    "        parent, X = stack.pop()\n",
    "\n",
    "    return sparent.accessors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer = Lexer()\n",
    "\n",
    "tokens = lexer.perform_tokenize(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = top_down(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node:Programm, value:0\n",
      "\tEnd Node:4(10,22):E\n",
      "\tNode:ListRules, value:1\n",
      "\t\tNode:OneRule, value:4\n",
      "\t\t\tEnd Node:6(43,44):<\n",
      "\t\t\tEnd Node:3(44,45):E\n",
      "\t\t\tNode:Stmt_RHS, value:5\n",
      "\t\t\t\tNode:Stmt_RHSTerm, value:9\n",
      "\t\t\t\t\tEnd Node:6(47,48):<\n",
      "\t\t\t\t\tNode:RHS_Stmt_Factor, value:15\n",
      "\t\t\t\t\t\tEnd Node:3(48,49):T\n",
      "\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:11\n",
      "\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:15\n",
      "\t\t\t\t\t\t\tEnd Node:3(50,52):E'\n",
      "\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:12\n",
      "\t\t\t\t\tEnd Node:7(52,53):>\n",
      "\t\t\t\tNode:Stmt_RestListRHS, value:7\n",
      "\t\t\tEnd Node:7(53,54):>\n",
      "\t\tNode:RestListRules, value:2\n",
      "\t\t\tNode:OneRule, value:4\n",
      "\t\t\t\tEnd Node:6(75,76):<\n",
      "\t\t\t\tEnd Node:3(76,78):E'\n",
      "\t\t\t\tNode:Stmt_RHS, value:5\n",
      "\t\t\t\t\tNode:Stmt_RHSTerm, value:9\n",
      "\t\t\t\t\t\tEnd Node:6(79,80):<\n",
      "\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:14\n",
      "\t\t\t\t\t\t\tEnd Node:2(80,81):+\n",
      "\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:11\n",
      "\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:15\n",
      "\t\t\t\t\t\t\t\tEnd Node:3(82,83):T\n",
      "\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:11\n",
      "\t\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:15\n",
      "\t\t\t\t\t\t\t\t\tEnd Node:3(84,86):E'\n",
      "\t\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:12\n",
      "\t\t\t\t\t\tEnd Node:7(86,87):>\n",
      "\t\t\t\t\tNode:Stmt_RestListRHS, value:6\n",
      "\t\t\t\t\t\tNode:Stmt_RHSTerm, value:9\n",
      "\t\t\t\t\t\t\tEnd Node:6(88,89):<\n",
      "\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:16\n",
      "\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:12\n",
      "\t\t\t\t\t\t\tEnd Node:7(89,90):>\n",
      "\t\t\t\t\t\tNode:Stmt_RestListRHS, value:7\n",
      "\t\t\t\tEnd Node:7(90,91):>\n",
      "\t\t\tNode:RestListRules, value:2\n",
      "\t\t\t\tNode:OneRule, value:4\n",
      "\t\t\t\t\tEnd Node:6(93,94):<\n",
      "\t\t\t\t\tEnd Node:3(94,95):T\n",
      "\t\t\t\t\tNode:Stmt_RHS, value:5\n",
      "\t\t\t\t\t\tNode:Stmt_RHSTerm, value:9\n",
      "\t\t\t\t\t\t\tEnd Node:6(97,98):<\n",
      "\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:15\n",
      "\t\t\t\t\t\t\t\tEnd Node:3(98,99):F\n",
      "\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:11\n",
      "\t\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:15\n",
      "\t\t\t\t\t\t\t\t\tEnd Node:3(100,102):T'\n",
      "\t\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:12\n",
      "\t\t\t\t\t\t\tEnd Node:7(102,103):>\n",
      "\t\t\t\t\t\tNode:Stmt_RestListRHS, value:7\n",
      "\t\t\t\t\tEnd Node:7(103,104):>\n",
      "\t\t\t\tNode:RestListRules, value:2\n",
      "\t\t\t\t\tNode:OneRule, value:4\n",
      "\t\t\t\t\t\tEnd Node:6(105,106):<\n",
      "\t\t\t\t\t\tEnd Node:3(106,108):T'\n",
      "\t\t\t\t\t\tNode:Stmt_RHS, value:5\n",
      "\t\t\t\t\t\t\tNode:Stmt_RHSTerm, value:9\n",
      "\t\t\t\t\t\t\t\tEnd Node:6(109,110):<\n",
      "\t\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:14\n",
      "\t\t\t\t\t\t\t\t\tEnd Node:2(110,111):*\n",
      "\t\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:11\n",
      "\t\t\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:15\n",
      "\t\t\t\t\t\t\t\t\t\tEnd Node:3(112,113):F\n",
      "\t\t\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:11\n",
      "\t\t\t\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:15\n",
      "\t\t\t\t\t\t\t\t\t\t\tEnd Node:3(114,116):T'\n",
      "\t\t\t\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:12\n",
      "\t\t\t\t\t\t\t\tEnd Node:7(116,117):>\n",
      "\t\t\t\t\t\t\tNode:Stmt_RestListRHS, value:6\n",
      "\t\t\t\t\t\t\t\tNode:Stmt_RHSTerm, value:9\n",
      "\t\t\t\t\t\t\t\t\tEnd Node:6(139,140):<\n",
      "\t\t\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:16\n",
      "\t\t\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:12\n",
      "\t\t\t\t\t\t\t\t\tEnd Node:7(140,141):>\n",
      "\t\t\t\t\t\t\t\tNode:Stmt_RestListRHS, value:7\n",
      "\t\t\t\t\t\tEnd Node:7(141,142):>\n",
      "\t\t\t\t\tNode:RestListRules, value:2\n",
      "\t\t\t\t\t\tNode:OneRule, value:4\n",
      "\t\t\t\t\t\t\tEnd Node:6(143,144):<\n",
      "\t\t\t\t\t\t\tEnd Node:3(144,145):F\n",
      "\t\t\t\t\t\t\tNode:Stmt_RHS, value:5\n",
      "\t\t\t\t\t\t\t\tNode:Stmt_RHSTerm, value:9\n",
      "\t\t\t\t\t\t\t\t\tEnd Node:6(147,148):<\n",
      "\t\t\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:14\n",
      "\t\t\t\t\t\t\t\t\t\tEnd Node:2(148,149):n\n",
      "\t\t\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:12\n",
      "\t\t\t\t\t\t\t\t\tEnd Node:7(149,150):>\n",
      "\t\t\t\t\t\t\t\tNode:Stmt_RestListRHS, value:6\n",
      "\t\t\t\t\t\t\t\t\tNode:Stmt_RHSTerm, value:9\n",
      "\t\t\t\t\t\t\t\t\t\tEnd Node:6(151,152):<\n",
      "\t\t\t\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:14\n",
      "\t\t\t\t\t\t\t\t\t\t\tEnd Node:2(152,153):(\n",
      "\t\t\t\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:11\n",
      "\t\t\t\t\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:15\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tEnd Node:3(154,155):E\n",
      "\t\t\t\t\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:10\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tNode:RHS_Stmt_Factor, value:14\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\tEnd Node:2(156,157):)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tNode:RestListRHSTerm_Stmt, value:12\n",
      "\t\t\t\t\t\t\t\t\t\tEnd Node:7(157,158):>\n",
      "\t\t\t\t\t\t\t\t\tNode:Stmt_RestListRHS, value:7\n",
      "\t\t\t\t\t\t\tEnd Node:7(158,159):>\n",
      "\t\t\t\t\t\tNode:RestListRules, value:3\n"
     ]
    }
   ],
   "source": [
    "v.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
