{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum, auto\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tag(Enum):\n",
    "    ERROR = auto()\n",
    "    TERM = auto()\n",
    "    NTERM = auto()\n",
    "    AXIOM = auto()\n",
    "    COMMENT = auto()\n",
    "    OPEN = auto()\n",
    "    CLOSE = auto()\n",
    "    UNMATCHED = auto()\n",
    "    END = auto()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Token:\n",
    "    \"\"\"Represents tokens for lexical analysis.\"\"\"\n",
    "\n",
    "    tag: Tag   \n",
    "    value: str = \"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CoordsToken(Token):\n",
    "    start_idx: int = 0\n",
    "    end_idx: int = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.tag} ({self.start_idx}, {self.end_idx}): {self.value}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    \"\"\"Performs lexical analysis of input data.\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        self.config = config\n",
    "        self._re_mapping = {\n",
    "            r\"'.*\\n\": Tag.COMMENT,\n",
    "            r\"<axiom <({})>>\\n\".format(config[\"nonterminal\"]): Tag.AXIOM,\n",
    "            config[\"open\"]: Tag.OPEN,\n",
    "            config[\"close\"]: Tag.CLOSE,\n",
    "            config[\"terminal\"]: Tag.TERM,\n",
    "            config[\"nonterminal\"]: Tag.NTERM,   \n",
    "        }\n",
    "\n",
    "    def _match_token(self, input_str: str) -> Token:\n",
    "        for pattern, tag in self._re_mapping.items():\n",
    "            matched = re.match(pattern, input_str)\n",
    "            if matched:\n",
    "                return Token(tag=tag, value=matched.group())\n",
    "\n",
    "        return Token(tag=Tag.UNMATCHED, value=input_str[0])\n",
    "\n",
    "    def tokenize(self, input_str: str) -> Queue:\n",
    "        tokens = Queue()\n",
    "        idx = 0\n",
    "\n",
    "        while idx < len(input_str):\n",
    "            token = self._match_token(input_str[idx:])\n",
    "            if token.tag == Tag.UNMATCHED and token.value.isspace() or token.tag == Tag.COMMENT:\n",
    "                idx += len(token.value)\n",
    "            else:\n",
    "                if token.tag == Tag.AXIOM:\n",
    "                    axiom_value = re.search(self.config[\"nonterminal\"], token.value).group(0) # type: ignore\n",
    "                    tokens.put(CoordsToken(Tag.AXIOM, axiom_value, idx, idx + len(token.value)))\n",
    "                else:\n",
    "                    tokens.put(CoordsToken(token.tag, token.value, idx, idx + len(token.value)))\n",
    "                idx += len(token.value)\n",
    "\n",
    "        tokens.put(CoordsToken(Tag.END, \"\", idx+1, idx+1))\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"open\": \"<\",\n",
    "    \"close\": \">\",\n",
    "    \"terminal\": r\"[a-z\\(\\)\\+\\*]\",\n",
    "    \"nonterminal\": r\"[A-Z]'?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nonterminal:\n",
    "    def __init__(self, symbol, rule_id=0):\n",
    "        self.symbol = symbol\n",
    "        self.rule_id = rule_id\n",
    "        self.children = []\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (isinstance(other, Nonterminal) and\n",
    "                self.symbol == other.symbol)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.symbol)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.symbol\n",
    "    \n",
    "    def print(self, indent):\n",
    "        print(indent + str(self) + \":\")\n",
    "        for child in self.children:\n",
    "            child.print(indent + \"\\t\")\n",
    "\n",
    "\n",
    "class Terminal:\n",
    "    def __init__(self, symbol):\n",
    "        self.symbol = symbol\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (isinstance(other, Terminal) and\n",
    "                self.symbol == other.symbol)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.symbol)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.symbol\n",
    "    \n",
    "    def print(self, indent):\n",
    "        print(indent + str(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table:\n",
    "    def __init__(self):\n",
    "        self.rule_ids = iter(range(100))\n",
    "        self.mapping = {\n",
    "            (Nonterminal(\"Grammar\"), Tag.AXIOM): ([Terminal(\"Axiom\"), Nonterminal(\"Rules\")], next(self.rule_ids)),\n",
    "            (Nonterminal(\"Rules\"), Tag.OPEN): ([Nonterminal(\"Rule\"), Nonterminal(\"RestRules\")], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RestRules\"), Tag.OPEN): ([Nonterminal(\"Rule\"), Nonterminal(\"RestRules\")], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RestRules\"), Tag.END): ([], next(self.rule_ids)),\n",
    "            (Nonterminal(\"Rule\"), Tag.OPEN): ([Terminal(\"Open\"), Terminal(\"Nterm\"), Nonterminal(\"RHS\"), Terminal(\"Close\")], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RHS\"), Tag.OPEN): ([Nonterminal(\"RHSTerm\"), Nonterminal(\"RestRHS\")], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RestRHS\"), Tag.OPEN): ([Nonterminal(\"RHSTerm\"), Nonterminal(\"RestRHS\")], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RestRHS\"), Tag.CLOSE): ([], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RestRHS\"), Tag.END): ([], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RHSTerm\"), Tag.OPEN): ([Terminal(\"Open\"), Nonterminal(\"RHSFactor\"), Nonterminal(\"RestRHSTerm\"), Terminal(\"Close\")], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RestRHSTerm\"), Tag.TERM): ([Nonterminal(\"RHSFactor\"), Nonterminal(\"RestRHSTerm\")], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RestRHSTerm\"), Tag.NTERM): ([Nonterminal(\"RHSFactor\"), Nonterminal(\"RestRHSTerm\")], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RestRHSTerm\"), Tag.CLOSE): ([], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RestRHSTerm\"), Tag.END): ([], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RHSFactor\"), Tag.TERM): ([Terminal(\"Term\")], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RHSFactor\"), Tag.NTERM): ([Terminal(\"Nterm\")], next(self.rule_ids)),\n",
    "            (Nonterminal(\"RHSFactor\"), Tag.CLOSE): ([], next(self.rule_ids)),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "      \n",
    "    def print(self, indent=\"\"):\n",
    "        print(f\"{indent}Leaf: {self.token}\")\n",
    "\n",
    "class Inner:\n",
    "    def __init__(self, nterm, rule_id):\n",
    "        self.nterm = nterm\n",
    "        self.rule_id = rule_id\n",
    "        self.children = []\n",
    "      \n",
    "    def print(self, indent=\"\"):\n",
    "        print(f\"{indent}Inner Node: {self.nterm}, rule: {self.rule_id}:\")\n",
    "        for child in self.children:\n",
    "            child.print(indent + \"\\t\")\n",
    "\n",
    "\n",
    "def top_down(tokens):\n",
    "    type_mapping = {\n",
    "        Tag.AXIOM: \"Axiom\",\n",
    "        Tag.TERM: \"Term\",\n",
    "        Tag.NTERM: \"Nterm\",\n",
    "        Tag.OPEN: \"Open\",\n",
    "        Tag.CLOSE: \"Close\"\n",
    "    }\n",
    "\n",
    "    delta = Table()\n",
    "    sparent = Inner(None, None)\n",
    "    stack = [(sparent, Terminal('$')), (sparent, Nonterminal('Grammar'))]\n",
    "\n",
    "    token = tokens.get()\n",
    "    parent, X = stack.pop()\n",
    "    \n",
    "    while X.symbol != '$':\n",
    "        if isinstance(X, Terminal):\n",
    "            if X.symbol == type_mapping[token.tag]:\n",
    "                parent.children.append(Leaf(token))\n",
    "                token = tokens.get()\n",
    "            else:\n",
    "                raise ValueError(f\"T. Ожидался {X}, Получен {token}\")\n",
    "        elif (X, token.tag) in delta.mapping.keys():\n",
    "            inner = Inner(X, delta.mapping[X, token.tag][1])\n",
    "            parent.children.append(inner)\n",
    "            for elem in delta.mapping[X, token.tag][0][::-1]:\n",
    "                stack.append((inner, elem))\n",
    "        else:\n",
    "            raise ValueError(f\"Ожидался {X}, Получен {token}\")\n",
    "        \n",
    "        parent, X = stack.pop()\n",
    "\n",
    "    return sparent.children[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer = Lexer(config)\n",
    "\n",
    "test_str = \"\"\"' аксиома\n",
    "<axiom <E>>\n",
    "' правила грамматики\n",
    "<E  <T E'>>\n",
    "' и это комментарий\n",
    "<E' <+ T E'> <>> \n",
    "<T  <F T'>>\n",
    "<T' <* F T'> 'и это комментарий\n",
    "\n",
    " <>>\n",
    "<F  <n> <( E )>>\"\"\"\n",
    "\n",
    "tokens = lexer.tokenize(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = top_down(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Node: Grammar, rule: 0:\n",
      "\tLeaf: Tag.AXIOM (10, 22): E\n",
      "\tInner Node: Rules, rule: 1:\n",
      "\t\tInner Node: Rule, rule: 4:\n",
      "\t\t\tLeaf: Tag.OPEN (43, 44): <\n",
      "\t\t\tLeaf: Tag.NTERM (44, 45): E\n",
      "\t\t\tInner Node: RHS, rule: 5:\n",
      "\t\t\t\tInner Node: RHSTerm, rule: 9:\n",
      "\t\t\t\t\tLeaf: Tag.OPEN (47, 48): <\n",
      "\t\t\t\t\tInner Node: RHSFactor, rule: 15:\n",
      "\t\t\t\t\t\tLeaf: Tag.NTERM (48, 49): T\n",
      "\t\t\t\t\tInner Node: RestRHSTerm, rule: 11:\n",
      "\t\t\t\t\t\tInner Node: RHSFactor, rule: 15:\n",
      "\t\t\t\t\t\t\tLeaf: Tag.NTERM (50, 52): E'\n",
      "\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 12:\n",
      "\t\t\t\t\tLeaf: Tag.CLOSE (52, 53): >\n",
      "\t\t\t\tInner Node: RestRHS, rule: 7:\n",
      "\t\t\tLeaf: Tag.CLOSE (53, 54): >\n",
      "\t\tInner Node: RestRules, rule: 2:\n",
      "\t\t\tInner Node: Rule, rule: 4:\n",
      "\t\t\t\tLeaf: Tag.OPEN (75, 76): <\n",
      "\t\t\t\tLeaf: Tag.NTERM (76, 78): E'\n",
      "\t\t\t\tInner Node: RHS, rule: 5:\n",
      "\t\t\t\t\tInner Node: RHSTerm, rule: 9:\n",
      "\t\t\t\t\t\tLeaf: Tag.OPEN (79, 80): <\n",
      "\t\t\t\t\t\tInner Node: RHSFactor, rule: 14:\n",
      "\t\t\t\t\t\t\tLeaf: Tag.TERM (80, 81): +\n",
      "\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 11:\n",
      "\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 15:\n",
      "\t\t\t\t\t\t\t\tLeaf: Tag.NTERM (82, 83): T\n",
      "\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 11:\n",
      "\t\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 15:\n",
      "\t\t\t\t\t\t\t\t\tLeaf: Tag.NTERM (84, 86): E'\n",
      "\t\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 12:\n",
      "\t\t\t\t\t\tLeaf: Tag.CLOSE (86, 87): >\n",
      "\t\t\t\t\tInner Node: RestRHS, rule: 6:\n",
      "\t\t\t\t\t\tInner Node: RHSTerm, rule: 9:\n",
      "\t\t\t\t\t\t\tLeaf: Tag.OPEN (88, 89): <\n",
      "\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 16:\n",
      "\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 12:\n",
      "\t\t\t\t\t\t\tLeaf: Tag.CLOSE (89, 90): >\n",
      "\t\t\t\t\t\tInner Node: RestRHS, rule: 7:\n",
      "\t\t\t\tLeaf: Tag.CLOSE (90, 91): >\n",
      "\t\t\tInner Node: RestRules, rule: 2:\n",
      "\t\t\t\tInner Node: Rule, rule: 4:\n",
      "\t\t\t\t\tLeaf: Tag.OPEN (93, 94): <\n",
      "\t\t\t\t\tLeaf: Tag.NTERM (94, 95): T\n",
      "\t\t\t\t\tInner Node: RHS, rule: 5:\n",
      "\t\t\t\t\t\tInner Node: RHSTerm, rule: 9:\n",
      "\t\t\t\t\t\t\tLeaf: Tag.OPEN (97, 98): <\n",
      "\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 15:\n",
      "\t\t\t\t\t\t\t\tLeaf: Tag.NTERM (98, 99): F\n",
      "\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 11:\n",
      "\t\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 15:\n",
      "\t\t\t\t\t\t\t\t\tLeaf: Tag.NTERM (100, 102): T'\n",
      "\t\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 12:\n",
      "\t\t\t\t\t\t\tLeaf: Tag.CLOSE (102, 103): >\n",
      "\t\t\t\t\t\tInner Node: RestRHS, rule: 7:\n",
      "\t\t\t\t\tLeaf: Tag.CLOSE (103, 104): >\n",
      "\t\t\t\tInner Node: RestRules, rule: 2:\n",
      "\t\t\t\t\tInner Node: Rule, rule: 4:\n",
      "\t\t\t\t\t\tLeaf: Tag.OPEN (105, 106): <\n",
      "\t\t\t\t\t\tLeaf: Tag.NTERM (106, 108): T'\n",
      "\t\t\t\t\t\tInner Node: RHS, rule: 5:\n",
      "\t\t\t\t\t\t\tInner Node: RHSTerm, rule: 9:\n",
      "\t\t\t\t\t\t\t\tLeaf: Tag.OPEN (109, 110): <\n",
      "\t\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 14:\n",
      "\t\t\t\t\t\t\t\t\tLeaf: Tag.TERM (110, 111): *\n",
      "\t\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 11:\n",
      "\t\t\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 15:\n",
      "\t\t\t\t\t\t\t\t\t\tLeaf: Tag.NTERM (112, 113): F\n",
      "\t\t\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 11:\n",
      "\t\t\t\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 15:\n",
      "\t\t\t\t\t\t\t\t\t\t\tLeaf: Tag.NTERM (114, 116): T'\n",
      "\t\t\t\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 12:\n",
      "\t\t\t\t\t\t\t\tLeaf: Tag.CLOSE (116, 117): >\n",
      "\t\t\t\t\t\t\tInner Node: RestRHS, rule: 6:\n",
      "\t\t\t\t\t\t\t\tInner Node: RHSTerm, rule: 9:\n",
      "\t\t\t\t\t\t\t\t\tLeaf: Tag.OPEN (139, 140): <\n",
      "\t\t\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 16:\n",
      "\t\t\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 12:\n",
      "\t\t\t\t\t\t\t\t\tLeaf: Tag.CLOSE (140, 141): >\n",
      "\t\t\t\t\t\t\t\tInner Node: RestRHS, rule: 7:\n",
      "\t\t\t\t\t\tLeaf: Tag.CLOSE (141, 142): >\n",
      "\t\t\t\t\tInner Node: RestRules, rule: 2:\n",
      "\t\t\t\t\t\tInner Node: Rule, rule: 4:\n",
      "\t\t\t\t\t\t\tLeaf: Tag.OPEN (143, 144): <\n",
      "\t\t\t\t\t\t\tLeaf: Tag.NTERM (144, 145): F\n",
      "\t\t\t\t\t\t\tInner Node: RHS, rule: 5:\n",
      "\t\t\t\t\t\t\t\tInner Node: RHSTerm, rule: 9:\n",
      "\t\t\t\t\t\t\t\t\tLeaf: Tag.OPEN (147, 148): <\n",
      "\t\t\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 14:\n",
      "\t\t\t\t\t\t\t\t\t\tLeaf: Tag.TERM (148, 149): n\n",
      "\t\t\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 12:\n",
      "\t\t\t\t\t\t\t\t\tLeaf: Tag.CLOSE (149, 150): >\n",
      "\t\t\t\t\t\t\t\tInner Node: RestRHS, rule: 6:\n",
      "\t\t\t\t\t\t\t\t\tInner Node: RHSTerm, rule: 9:\n",
      "\t\t\t\t\t\t\t\t\t\tLeaf: Tag.OPEN (151, 152): <\n",
      "\t\t\t\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 14:\n",
      "\t\t\t\t\t\t\t\t\t\t\tLeaf: Tag.TERM (152, 153): (\n",
      "\t\t\t\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 11:\n",
      "\t\t\t\t\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 15:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tLeaf: Tag.NTERM (154, 155): E\n",
      "\t\t\t\t\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 10:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tInner Node: RHSFactor, rule: 14:\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\tLeaf: Tag.TERM (156, 157): )\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tInner Node: RestRHSTerm, rule: 12:\n",
      "\t\t\t\t\t\t\t\t\t\tLeaf: Tag.CLOSE (157, 158): >\n",
      "\t\t\t\t\t\t\t\t\tInner Node: RestRHS, rule: 7:\n",
      "\t\t\t\t\t\t\tLeaf: Tag.CLOSE (158, 159): >\n",
      "\t\t\t\t\t\tInner Node: RestRules, rule: 3:\n"
     ]
    }
   ],
   "source": [
    "v.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
